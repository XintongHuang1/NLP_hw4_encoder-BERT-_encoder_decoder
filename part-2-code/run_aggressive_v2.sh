#!/bin/bash

# æ¿€è¿›ä¼˜åŒ–ç‰ˆæœ¬ - é’ˆå¯¹ä½F1é—®é¢˜
# å…³é”®æ”¹è¿›ï¼š
# 1. ç§»é™¤äº†å¯èƒ½æœ‰é—®é¢˜çš„å®ä½“å¯¹é½
# 2. æ›´å¥½çš„prompt: "translate to SQL for flight database: "
# 3. æ›´å¼ºçš„ç”Ÿæˆå‚æ•°: beam=10, max_tokens=200
# 4. æ›´å¤§çš„å­¦ä¹ ç‡: 3e-4 (å­¦ä¹ æ›´å¿«)

echo "========================================"
echo "ğŸš€ æ¿€è¿›ä¼˜åŒ–è®­ç»ƒ - V2"
echo "========================================"
echo ""
echo "æ”¹è¿›ç‚¹:"
echo "  âœ… ç§»é™¤å®ä½“å¯¹é½ (å¯èƒ½å¼•å…¥é”™è¯¯)"
echo "  âœ… æ”¹è¿›prompt (æ›´æ¸…æ™°)"
echo "  âœ… å¢å¼ºç”Ÿæˆ (beam=10, tokens=200)"
echo "  âœ… æé«˜å­¦ä¹ ç‡ (3e-4)"
echo ""

# æ¨èé…ç½®
python train_t5.py --finetune --experiment_name "aggressive_v2" --max_n_epochs 25

echo ""
echo "========================================"
echo "å¤‡é€‰æ–¹æ¡ˆï¼ˆå¦‚æœä¸Šé¢ä¸å¤Ÿå¥½ï¼‰ï¼š"
echo "========================================"
echo ""

echo "æ–¹æ¡ˆA: æ›´æ¿€è¿›çš„å­¦ä¹ ç‡ (5e-4)"
echo "python train_t5.py --finetune --learning_rate 5e-4 --max_n_epochs 25 --experiment_name 'lr_5e4'"
echo ""

echo "æ–¹æ¡ˆB: ç»„åˆä¼˜åŒ– + æ›´å¤§batch"
echo "python train_t5.py --finetune --batch_size 32 --max_n_epochs 30 --experiment_name 'batch32_long'"
echo ""

echo "æ–¹æ¡ˆC: å°è¯•T5-small (æ›´å¿«ï¼Œå¯èƒ½æ›´ç¨³å®š)"
echo "# éœ€è¦ä¿®æ”¹ t5_utils.py ä¸­çš„ model_name = 'google-t5/t5-small'"
